{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from compare_wandb import load_full_df, get_test_pdbs, load_run_dict\n",
    "\n",
    "import wandb\n",
    "api = wandb.Api()\n",
    "entity = 'proteins'\n",
    "project = 'iclr2021-rebuttal'\n",
    "\n",
    "import boto3\n",
    "import os\n",
    "s3 = boto3.client(\"s3\")\n",
    "s3_bucket = \"proteindata\"\n",
    "\n",
    "import torch\n",
    "\n",
    "# load metatest pdbs\n",
    "with open('metatest_fams.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    metatest_pdbs = [l.strip() for l in lines]\n",
    "\n",
    "from mogwai import models\n",
    "from mogwai.utils.functional import apc\n",
    "model_name = 'factored_attention'\n",
    "fatt_model = models.get(model_name)\n",
    "gremlin_model = models.get('gremlin')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams.update({\n",
    "#     \"text.usetex\": True,\n",
    "#     \"font.family\": \"serif\",\n",
    "#     \"font.serif\": [\"Times\"],\n",
    "#     \"font.size\": 8,\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 748/748 [00:00<00:00, 32669.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bxnkt0uq has 748 runs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 748/748 [00:00<00:00, 33597.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xuofwjtc has 748 runs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 748/748 [00:00<00:00, 36077.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kqe7or39 has 748 runs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 748/748 [00:00<00:00, 34378.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32emd6ri has 748 runs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2233 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8yi6a4w5 has 2233 runs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2233/2233 [00:03<00:00, 592.58it/s]\n"
     ]
    }
   ],
   "source": [
    "head_sweep_runs = {\n",
    "    'fatt-metatest-head-sweep-512': 'bxnkt0uq',\n",
    "    'fatt-metatest-head-256': 'xuofwjtc',\n",
    "    'fatt-metatest-head-sweep-64-kqe7or39': 'kqe7or39',\n",
    "    'fatt-metatest-head-sweep-128': '32emd6ri',\n",
    "    'fatt-metatest-head-sweep-8-32': '8yi6a4w5',\n",
    "}\n",
    "\n",
    "dict_of_dfs = load_run_dict(head_sweep_runs)\n",
    "fatt_df = pd.concat(list(dict_of_dfs.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 748/748 [00:00<00:00, 34646.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbuvl02g has 748 runs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gremlin_runs = {'gremlin': 'dbuvl02g'}\n",
    "gremlin_df_dict = load_run_dict(gremlin_runs)\n",
    "gremlin_df = pd.concat(list(gremlin_df_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_statedict(run_id, dest='fatt.h5'):\n",
    "    run = api.run(f\"{entity}/{project}/{run_id}\")\n",
    "    key = os.path.join(\"iclr-2021-factored-attention\", *run.path, \"model_state_dict.h5\")\n",
    "    with open(dest, 'wb') as f:\n",
    "        s3.download_fileobj(s3_bucket, key, f)\n",
    "    return dest\n",
    "\n",
    "def get_fatt_run_id(pdb, attention_head_size, num_attention_heads, df):\n",
    "    run_id = df[(df['pdb']==pdb) & (df['num_attention_heads']==num_attention_heads)]['run_id'].values\n",
    "    return run_id[0]\n",
    "\n",
    "def get_gremlin_run_id(pdb, df):\n",
    "    run_id = df[df['pdb']==pdb]['run_id'].values\n",
    "    return run_id[0]\n",
    "\n",
    "def get_gremlin_statedict(pdb, gremlin_df, dest='gremlin.h5'):\n",
    "    run_id = get_gremlin_run_id(pdb, gremlin_df)\n",
    "    f_statedict = download_statedict(run_id, dest=dest)\n",
    "    statedict = torch.load(f_statedict)\n",
    "    return statedict\n",
    "\n",
    "def get_fatt_statedict(pdb, num_attention_heads, fatt_df, attention_head_size=32, dest='fatt.h5'):\n",
    "    run_id = get_fatt_run_id(pdb, attention_head_size, num_attention_heads, fatt_df)\n",
    "    f_statedict = download_statedict(run_id, dest=f'fatt_{num_attention_heads}.h5')\n",
    "    statedict = torch.load(f_statedict)\n",
    "    return statedict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert-results\t\t\t     Makefile\r\n",
      "compare_wandb.py\t\t     metatest_fams.txt\r\n",
      "contact_maps_2bfw.pdf\t\t     mogwai\r\n",
      "contact_potts_3n2a_1_A_p_at_L_5.pdf  num_heads_sweep_df.pkl\r\n",
      "contact_potts_3n2a_1_A_p_at_L.pdf    paper_figs_no_weights.ipynb\r\n",
      "data\t\t\t\t     plot_contacts_for_run_fig2.ipynb\r\n",
      "download_data.sh\t\t     potts_3n2a_1_A.pdf\r\n",
      "fatt.h5\t\t\t\t     predicted_contacts.npy\r\n",
      "fatt-pl-results\t\t\t     protbert_test_proteins.txt\r\n",
      "fatt_transfer.py\t\t     __pycache__\r\n",
      "fig2_2bfw_contacts.pdf\t\t     randomize_value_weights.py\r\n",
      "fig2_2bfw_contacts.png\t\t     README.md\r\n",
      "gremlin-contacts\t\t     requirements.txt\r\n",
      "gremlin.h5\t\t\t     roshan_contact_maps.ipynb\r\n",
      "gremlin-results\t\t\t     sampled_pdbs.txt\r\n",
      "head_size_sweep.ipynb\t\t     spagonerincon.npy\r\n",
      "iclr2021-rebuttal\t\t     train.py\r\n",
      "launch_jobs.sh\t\t\t     true_contacts.npy\r\n",
      "launch_shards.sh\t\t     venv\r\n",
      "launch_weight_comparison.py\t     wandb\r\n",
      "LICENSE\t\t\t\t     wandb-configs\r\n",
      "loggers.py\t\t\t     weight_correlations.ipynb\r\n",
      "main_figs.ipynb\t\t\t     weight_correlations.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gremlin_statedict = get_gremlin_statedict('2bfw_1_A', gremlin_df)\n",
    "fatt_statedict = get_fatt_statedict('2bfw_1_A', 32, fatt_df)\n",
    "\n",
    "q = fatt_statedict['query']\n",
    "k = fatt_statedict['key']\n",
    "v = fatt_statedict['value']\n",
    "\n",
    "w = gremlin_statedict['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([196, 32, 32]) torch.Size([196, 32, 32]) torch.Size([32, 20, 20]) torch.Size([196, 20, 196, 20])\n"
     ]
    }
   ],
   "source": [
    "print(q.shape, k.shape, v.shape, w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_msa_hparams(pdb, df):\n",
    "    pdb = df[df['pdb']==pdb]\n",
    "    hparam_dict = pdb.to_dict()\n",
    "    msa_length = int(list(hparam_dict['msa_length'].values())[0])\n",
    "    num_seqs = int(list(hparam_dict['num_seqs'].values())[0])\n",
    "    return {'msa_length': msa_length, 'num_seqs': num_seqs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_correlations(w, w_fatt, L, make_plot=False):\n",
    "    idx = np.triu_indices(L, 1)\n",
    "\n",
    "    fatt_w_no_diag = w_fatt.detach()[idx[0], :, idx[1], :]\n",
    "    gremlin_w_no_diag = w[idx[0], :, idx[1], :]\n",
    "\n",
    "    fatt_w_compare_idx = torch.flatten(fatt_w_no_diag)\n",
    "    gremlin_w_compare_idx = torch.flatten(gremlin_w_no_diag)\n",
    "    w_spearman = spearmanr(fatt_w_compare_idx, gremlin_w_compare_idx)[0]\n",
    "    w_pearson = pearsonr(fatt_w_compare_idx, gremlin_w_compare_idx)[0]\n",
    "    \n",
    "    if make_plot:\n",
    "        # plotting correlation\n",
    "        subset = np.random.choice(len(gremlin_w_compare_idx), size=100000) # plotting the whole thing takes time\n",
    "        plt.title(f'Spearman: {w_spearman:.2f} Pearson: {w_pearson:.2f} PDB: {pdb}')\n",
    "        plt.xlabel('gremlin w')\n",
    "        plt.ylabel('fatt w')\n",
    "        plt.xlim(-2, 2); plt.ylim(-2, 2)\n",
    "        plt.scatter(gremlin_w_compare_idx[subset], fatt_w_compare_idx[subset], s=1)\n",
    "        plt.show()\n",
    "    return w_spearman, w_pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mogwai.utils.functional import apc\n",
    "from mogwai.metrics import precisions_in_range\n",
    "\n",
    "def get_info(num_attention_heads, \n",
    "             pdb,\n",
    "             attention_head_size,\n",
    "             fatt_df=fatt_df, \n",
    "             gremlin_df=gremlin_df):\n",
    "    fatt_statedict = get_fatt_statedict(pdb, num_attention_heads, fatt_df, attention_head_size=attention_head_size, dest=f'fatt_{num_attention_heads}.h5')\n",
    "    gremlin_statedict = get_gremlin_statedict(pdb, gremlin_df, dest='gremlin.h5')\n",
    "    \n",
    "    hparams = get_msa_hparams(pdb, df=fatt_df)\n",
    "    msa_length = hparams['msa_length']\n",
    "    num_seqs = hparams['num_seqs']\n",
    "    hparams['attention_head_size'] = attention_head_size\n",
    "    hparams['num_attention_heads'] = num_attention_heads\n",
    "    # initialize a matrix, which will be overriden when we load later.\n",
    "    hparams['true_contacts'] = torch.ones([hparams['msa_length'], hparams['msa_length']])\n",
    "    model = fatt_model(**hparams)\n",
    "    model.load_state_dict(fatt_statedict)\n",
    "    \n",
    "    w_fatt = model.compute_mrf_weight()\n",
    "    w = gremlin_statedict['weight']\n",
    "    \n",
    "    metrics = {}\n",
    "    metrics['pdb'] = pdb\n",
    "    metrics['msa_length'] = msa_length\n",
    "    metrics['num_seqs'] = num_seqs\n",
    "    metrics['attention_head_size'] = attention_head_size\n",
    "    metrics['num_attention_heads'] = num_attention_heads\n",
    "    \n",
    "    predictions = apc(model.get_contacts())\n",
    "    targets = model._true_contacts\n",
    "    \n",
    "    short = precisions_in_range(predictions, targets, minsep=6, maxsep=13)\n",
    "    for k, v in short.items():\n",
    "        metrics[f'short_{k}'] = float(v.squeeze())\n",
    "    medium = precisions_in_range(predictions, targets, minsep=13, maxsep=25)\n",
    "    for k, v in medium.items():\n",
    "        metrics[f'medium_{k}'] = float(v.squeeze())\n",
    "    long = precisions_in_range(predictions, targets, minsep=13, maxsep=25)\n",
    "    for k, v in long.items():\n",
    "        metrics[f'long_{k}'] = float(v.squeeze())\n",
    "#     wspearman, wpearson = get_correlations(w, w_fatt, msa_length)\n",
    "#     metrics['w_spearman'] = wspearman\n",
    "#     metrics['w_pearson'] = wpearson\n",
    "#     metrics['predicted_contacts_apc'] = predictions\n",
    "#     metrics['true_contacts'] = targets\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n    return list(map(*args))\n  File \"<ipython-input-13-de691e4e0089>\", line 9, in get_info_map\n    return get_info(num_attention_heads, attention_head_size=32, pdb=pdb)\n  File \"<ipython-input-12-90fbef6b8838>\", line 9, in get_info\n    fatt_statedict = get_fatt_statedict(pdb, num_attention_heads, fatt_df, attention_head_size=attention_head_size, dest=f'fatt_{num_attention_heads}.h5')\n  File \"<ipython-input-6-3de2ab70191e>\", line 23, in get_fatt_statedict\n    run_id = get_fatt_run_id(pdb, attention_head_size, num_attention_heads, fatt_df)\n  File \"<ipython-input-6-3de2ab70191e>\", line 10, in get_fatt_run_id\n    return run_id[0]\nIndexError: index 0 is out of bounds for axis 0 with size 0\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-de691e4e0089>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mnew_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_info_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heads_sweep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         '''\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "\n",
    "info = []\n",
    "num_heads_sweep = [8, 16, 32, 64, 128, 256, 512]\n",
    "pdb = '2bfw_1_A'\n",
    "\n",
    "def get_info_map(num_attention_heads):\n",
    "    return get_info(num_attention_heads, attention_head_size=32, pdb=pdb)\n",
    "\n",
    "with Pool() as p:\n",
    "    new_info = p.map(get_info_map, num_heads_sweep)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = []\n",
    "\n",
    "for pdb in tqdm(metatest_pdbs[0:5]):\n",
    "    for num_attention_heads in num_heads_sweep:\n",
    "        info.append(get_info(num_attention_heads, attention_head_size=32, pdb=pdb))\n",
    "        \n",
    "sweep_df = pd.DataFrame.from_records(info)\n",
    "sweep_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "\n",
    "num_heads_sweep = [8, 16, 32, 64, 128, 256, 512]\n",
    "\n",
    "info = []\n",
    "try:\n",
    "    for pdb in tqdm(metatest_pdbs[1:2]):\n",
    "        get_info_map = partial(get_info, attention_head_size=32, pdb=pdb)\n",
    "        with Pool() as p:\n",
    "            new_info = p.map(get_info_map, num_heads_sweep)\n",
    "        for i in new_info:\n",
    "            info.append(i)\n",
    "finally:\n",
    "    print(pdb)\n",
    "    sweep_df = pd.DataFrame.from_records(info)\n",
    "    with open('num_head_sweep_df.pkl', 'wb') as f:\n",
    "        pkl.dump(sweep_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fatt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = []\n",
    "\n",
    "for index, row in tqdm(fatt_df.iterrows()):\n",
    "    info.append(get_info(num_attention_heads=row['num_attention_heads'], \n",
    "                         attention_head_size=row['attention_head_size'], \n",
    "                         pdb=row['pdb']))\n",
    "    if index > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row['num_seqs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = fatt_df.shape[0]\n",
    "fatt_df[:n//10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('num_heads_sweep_df.pkl', 'rb') as f:\n",
    "    sweep_df = pkl.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sweep_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(dpi=600)\n",
    "sns.violinplot(x=\"num_attention_heads\", \n",
    "               y=\"w_spearman\", \n",
    "               data=sweep_df)\n",
    "plt.title('spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(dpi=600)\n",
    "sns.violinplot(x=\"num_attention_heads\", \n",
    "               y=\"w_pearson\", \n",
    "               data=sweep_df)\n",
    "plt.title('pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(7., 3.5), dpi=600, ncols=3, sharey=True)\n",
    "\n",
    "melted_df = pd.melt(sweep_df, id_vars=['num_attention_heads'], value_vars=['short_pr_at_l_5', 'medium_pr_at_l_5', 'long_pr_at_l_5'])\n",
    "# plt.subplots(dpi=600)\n",
    "sns.catplot(x=\"variable\", \n",
    "            y=\"value\", \n",
    "            hue=\"num_attention_heads\",\n",
    "            data=melted_df, \n",
    "            kind=\"violin\",\n",
    "            height=10, \n",
    "            aspect=2)\n",
    "plt.title('short medium long L/5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_df = pd.melt(sweep_df, id_vars=['num_attention_heads'], value_vars=['short_pr_at_l', 'medium_pr_at_l', 'long_pr_at_l'])\n",
    "# plt.subplots(dpi=600)\n",
    "sns.catplot(x=\"variable\", \n",
    "            y=\"value\", \n",
    "            hue=\"num_attention_heads\",\n",
    "            data=melted_df, \n",
    "            kind=\"violin\",\n",
    "            height=10, \n",
    "            aspect=2)\n",
    "plt.title('short medium long L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
